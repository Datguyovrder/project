{
 "metadata": {
  "name": "",
  "signature": "sha256:71ec173d2bb0dc1cf4497440a5f5095af42219d389ce8b8d77c45594221eb472"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import ConfigParser\n",
      "from TwitterAPI import TwitterAPI\n",
      "import re\n",
      "from StringIO import StringIO\n",
      "from zipfile import ZipFile\n",
      "from urllib import urlopen\n",
      "import sys\n",
      "import pickle\n",
      "\n",
      "def get_twitter(config_file):\n",
      "    config = ConfigParser.ConfigParser()\n",
      "    config.read(config_file)\n",
      "    twitter = TwitterAPI(\n",
      "    config.get('twitter', 'consumer_key'),\n",
      "    config.get('twitter', 'consumer_secret'),\n",
      "    config.get('twitter', 'access_token'),\n",
      "    config.get('twitter', 'access_token_secret'))\n",
      "    return twitter\n",
      "\n",
      "def afinn_sentiment2(terms, afinn, verbose=False):\n",
      "    pos = 0\n",
      "    neg = 0\n",
      "\n",
      "    for t in terms:\n",
      "        if t in afinn:\n",
      "            if verbose:\n",
      "                print '\\t%s=%d' % (t, afinn[t])\n",
      "            if afinn[t] > 0:\n",
      "                pos += afinn[t]\n",
      "            else:\n",
      "                neg += -1 * afinn[t]\n",
      "    return pos, neg\n",
      "\n",
      "def tokenize(text):\n",
      "    return re.sub('\\W+', ' ', text.lower()).split()\n",
      "\n",
      "url = urlopen('http://www2.compute.dtu.dk/~faan/data/AFINN.zip')\n",
      "zipfile = ZipFile(StringIO(url.read()))\n",
      "afinn_file = zipfile.open('AFINN/AFINN-111.txt')\n",
      "afinn = dict()\n",
      "\n",
      "for line in afinn_file:\n",
      "    parts = line.strip().split()\n",
      "    if len(parts) == 2:\n",
      "        afinn[parts[0]] = int(parts[1])\n",
      "\n",
      "twitter = get_twitter('twitter.cfg')\n",
      "tweets = []\n",
      "\n",
      "for r in twitter.request('search/tweets', {'q': sys.argv[1], 'count': 100}):\n",
      "    tweets.append(r)\n",
      "\n",
      "pickle.dump(tweets,open(sys.argv[1]+'.pkl','wb'))\n",
      "tokens = [tokenize(t['text']) for t in tweets]\n",
      "positives = []\n",
      "negatives = []\n",
      "\n",
      "for tweet in tokens:\n",
      "    pos, neg = afinn_sentiment2(tweet, afinn)\n",
      "    if pos > neg:\n",
      "        positives.append((' '.join(tweet), pos, neg))\n",
      "    elif neg > pos:\n",
      "        negatives.append((' '.join(tweet), pos, neg))\n",
      "\n",
      "#for tweet, pos, neg in sorted(positives, key=lambda x: x[1], reverse=True):\n",
      "# print pos, neg, tweet\n",
      "rating = (1.0*len(positives)+1.0)/(len(positives)+len(negatives)+1.0)*100.0\n",
      "print rating\n",
      "\n",
      "with open(\"results.txt\", \"a\") as myfile:\n",
      "    myfile.write(sys.argv[1]+' '+str(rating)+'\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'text'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-f1c4f39d6406>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[0mpositives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0mnegatives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 'text'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}