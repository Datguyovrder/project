import ConfigParser
from TwitterAPI import TwitterAPI
import re
from StringIO import StringIO
from zipfile import ZipFile
from urllib import urlopen
import sys
import pickle

def get_twitter(config_file):
    config = ConfigParser.ConfigParser()
    config.read(config_file)
    twitter = TwitterAPI(
    config.get('twitter', 'consumer_key'),
    config.get('twitter', 'consumer_secret'),
    config.get('twitter', 'access_token'),
    config.get('twitter', 'access_token_secret'))
    return twitter

def afinn_sentiment2(terms, afinn, verbose=False):
    pos = 0
    neg = 0
    for t in terms:
        if t in afinn:
            if verbose:
                print '\t%s=%d' % (t, afinn[t])
            if afinn[t] > 0:
                pos += afinn[t]
            else:
                neg += -1 * afinn[t]
    return pos, neg

def tokenize(text):
    return re.sub('\W+', ' ', text.lower()).split()

url = urlopen('http://www2.compute.dtu.dk/~faan/data/AFINN.zip')
zipfile = ZipFile(StringIO(url.read()))
afinn_file = zipfile.open('AFINN/AFINN-111.txt')
afinn = dict()

for line in afinn_file:
    parts = line.strip().split()
    if len(parts) == 2:
        afinn[parts[0]] = int(parts[1])

twitter = get_twitter('twitter.cfg')
tweets = []
for r in twitter.request('search/tweets', {'q': sys.argv[1], 'count': 100}):
    tweets.append(r)

pickle.dump(tweets,open(sys.argv[1]+'.pkl','wb'))
tokens = [tokenize(t['text']) for t in tweets]
positives = []
negatives = []
for tweet in tokens:
    pos, neg = afinn_sentiment2(tweet, afinn)
    if pos > neg:
        positives.append((' '.join(tweet), pos, neg))
    elif neg > pos:
        negatives.append((' '.join(tweet), pos, neg))

rating = (1.0*len(positives)+1.0)/(len(positives)+len(negatives)+1.0)*100.0
print rating

with open("results.txt", "a") as myfile:
    myfile.write(sys.argv[1]+' '+str(rating)+'\n')
