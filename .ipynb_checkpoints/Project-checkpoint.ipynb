{
 "metadata": {
  "name": "",
  "signature": "sha256:bb8e76556d511d3b4edb95792f02107a1a0b85bc3e536e5ad0856786295b3524"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ConfigParser\n",
      "from TwitterAPI import TwitterAPI\n",
      "\n",
      "# This method is done for you.\n",
      "def get_twitter(config_file):\n",
      "    \"\"\" Read the config_file and construct an instance of TwitterAPI.\n",
      "    Args:\n",
      "      config_file ... A config file in ConfigParser format with Twitter credentials\n",
      "    Returns:\n",
      "      An instance of TwitterAPI.\n",
      "    \"\"\"\n",
      " \n",
      "    config = ConfigParser.ConfigParser()\n",
      "    config.read(config_file)\n",
      "    twitter = TwitterAPI(\n",
      "                   config.get('twitter', 'consumer_key'),\n",
      "                   config.get('twitter', 'consumer_secret'),\n",
      "                   config.get('twitter', 'access_token'),\n",
      "                   config.get('twitter', 'access_token_secret'))\n",
      "    return twitter\n",
      "\n",
      "twitter = get_twitter('twitter.cfg')\n",
      "print 'Established Twitter connection.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save streamed tweets to a file\n",
      "#each (full) file contains 10,000 tweets\n",
      "\n",
      "import pickle\n",
      "from datetime import datetime\n",
      "import sys\n",
      "import time\n",
      "\n",
      "playing_movies_list = ['OUIJA','GONE GIRL','JOHN WICK','FURY','BEST OF ME','ST VINCENT','BOOK OF LIFE']\n",
      "\n",
      "file_name = \"tweets \" + str(datetime.now()).split('.')[0].replace(':','_') + \".bin\"\n",
      "print \"starting new file: \" + file_name\n",
      "\n",
      "r = twitter.request('statuses/filter', {'track':playing_movies_list, 'filter_level':'low'})\n",
      "\n",
      "tweet_number = 1\n",
      "\n",
      "while True:\n",
      "    try:\n",
      "        for tweet in r:\n",
      "            print \"saved tweet %d from %s\" % (tweet_number, tweet['user']['name'])\n",
      "            pickle.dump(tweet, open(file_name, 'ab'))\n",
      "            tweet_number += 1\n",
      "            if tweet_number > 10000:\n",
      "                tweet_number = 1\n",
      "                file_name = \"tweets \" + str(datetime.now()).split('.')[0].replace(':','_') + \".bin\"\n",
      "                print \"starting new file: \" + file_name\n",
      "    except:\n",
      "        print >> sys.stderr, 'Streaming error...trying again in 30 seconds.'\n",
      "        sys.stderr.flush()\n",
      "        time.sleep(30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get a list of all files with saved tweets\n",
      "\n",
      "from os import listdir\n",
      "from os import getcwd\n",
      "from os.path import isfile, join\n",
      "\n",
      "def get_filenames():\n",
      "    #used two pages for creating this code...\n",
      "    #http://stackoverflow.com/questions/3430372/how-to-get-full-path-of-current-directory-in-python\n",
      "    #http://stackoverflow.com/questions/3207219/how-to-list-all-files-of-a-directory-in-python\n",
      "    tweet_files = [ f for f in listdir(getcwd()) if isfile(join(getcwd(),f)) and \"tweets\" in f and \".bin\" in f]\n",
      "    #print '\\n'.join(tweet_files)\n",
      "    return tweet_files\n",
      "print \"added\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create a mechanism to label/save a supervised set of tweets...\n",
      "def classify_tweet(tweet, loaded_tweet_num):\n",
      "    print str(loaded_tweet_num) + \") Tweet by user: \" + tweet['user']['name'] + \" on \" + tweet['created_at'].split('+')[0]\n",
      "    print tweet['text']\n",
      "    classification = input(\"Enter label (0 = neg, 1 = pos, 2 = ignore tweet, 3 = stop classifying): \")\n",
      "    while classification not in (0, 1, 2, 3):\n",
      "        print \"Incorrect input. Enter 0 for negative, 1 for positive, 2 for ignore tweet, 3 to stop classifying.\"\n",
      "        classification = input(\"Enter label (0 = neg, 1 = pos, 2 = ignore tweet, 3 = stop classifying): \")\n",
      "    return classification\n",
      "print \"added\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create a mechanism to label/save a supervised set of tweets...\n",
      "def print_tweet(tweet, loaded_tweet_num):\n",
      "    print str(loaded_tweet_num) + \") Tweet by user: \" + tweet['user']['name'] + \" on \" + tweet['created_at'].split('+')[0]\n",
      "    print tweet['text']\n",
      "print \"added\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "def save_labeled_tweet(tweet, label):\n",
      "    labeled_tweets_filename = \"labeled_tweet_s.bin\"\n",
      "    labeled_tweet = {'tweet':tweet, 'sentiment_label':label}\n",
      "    pickle.dump(labeled_tweet, open(labeled_tweets_filename, 'ab'))\n",
      "    if label == 1:\n",
      "        print \"positive tweet saved\"\n",
      "    elif label == 0:\n",
      "        print \"negative tweet saved\"\n",
      "print \"added\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#let's try to read back some of the tweets we saved!\n",
      "#I'll manually classify them, then save my work to a new file\n",
      "import pprint, pickle\n",
      "\n",
      "def open_tweets_files():\n",
      "    files = get_filenames()\n",
      "    \n",
      "    #A number of tweets to skip before classification prompts\n",
      "    skipct = 50\n",
      "    \n",
      "    classify = True\n",
      "    #classify = False #just print the tweet\n",
      "\n",
      "    stop_now = False #always start with this false\n",
      "    #stop_now = True #this is only for testing...\n",
      "    \n",
      "    for file_to_open in files:\n",
      "        print \"--------------------------------------------\"\n",
      "        print \"opening file: \" + file_to_open\n",
      "        print \"--------------------------------------------\"\n",
      "        pkl_file = open(file_to_open, 'rb')\n",
      "        loaded_tweet_num = 1\n",
      "        while True:\n",
      "            if skipct > 0:\n",
      "                skipct -= 1\n",
      "                continue\n",
      "            try:\n",
      "                tweet = pickle.load(pkl_file)\n",
      "                if tweet['lang'] != 'en':\n",
      "                    continue\n",
      "                if classify:\n",
      "                    classification = classify_tweet(tweet, loaded_tweet_num) \n",
      "                    if classification == 2:\n",
      "                        print \"ignoring tweet\"\n",
      "                    elif classification == 1:\n",
      "                        save_labeled_tweet(tweet, 1)\n",
      "                    elif classification == 0:\n",
      "                        save_labeled_tweet(tweet, 0)\n",
      "                    elif classification == 3:\n",
      "                        stop_now = True\n",
      "                    else:\n",
      "                        print \"classification error!\"\n",
      "                else:\n",
      "                    print_tweet(tweet, loaded_tweet_num)\n",
      "                loaded_tweet_num += 1\n",
      "            except EOFError:\n",
      "                break\n",
      "            if stop_now:\n",
      "                break\n",
      "        if stop_now:\n",
      "            print \"stopping classification\"\n",
      "            break\n",
      "        \n",
      "open_tweets_files()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pkl_file = open('labeled_tweet_s.bin', 'rb')\n",
      "loaded_tweet_num = 1\n",
      "while True:\n",
      "    try:\n",
      "        tweet = pickle.load(pkl_file)\n",
      "        print tweet['sentiment_label']\n",
      "        print tweet['tweet']['user']['name']\n",
      "    except EOFError:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ConfigParser\n",
      "from TwitterAPI import TwitterAPI\n",
      "import re\n",
      "from StringIO import StringIO\n",
      "from zipfile import ZipFile\n",
      "from urllib import urlopen\n",
      "import sys\n",
      "import pickle\n",
      "\n",
      "def tokenize(text):\n",
      "    return re.sub('\\W+', ' ', text.lower()).split()\n",
      "\n",
      "def afinn_sentiment(terms, afinn, verbose=False):\n",
      "    pos = 0\n",
      "    neg = 0\n",
      "    for t in terms:\n",
      "        if t in afinn:\n",
      "            if verbose:\n",
      "                print '\\t%s=%d' % (t, afinn[t])\n",
      "            if afinn[t] > 0:\n",
      "                pos += afinn[t]\n",
      "            else:\n",
      "                neg += -1 * afinn[t]\n",
      "    return pos, neg\n",
      "\n",
      "url = urlopen('http://www2.compute.dtu.dk/~faan/data/AFINN.zip')\n",
      "zipfile = ZipFile(StringIO(url.read()))\n",
      "afinn_file = zipfile.open('AFINN/AFINN-111.txt')\n",
      "afinn = dict()\n",
      "\n",
      "for line in afinn_file:\n",
      "    sections = line.strip().split()\n",
      "    if len(sections) == 2:\n",
      "        afinn[sections[0]] = int(sections[1])\n",
      "\n",
      "tweets = pickle.load(open(sys.argv[1]+'.pkl','rb'))\n",
      "print 'read %d tweets' % len(tweets)\n",
      "tokes = [tokenize(t['text']) for t in tweets]\n",
      "pos2 = []\n",
      "neg2 = []\n",
      "\n",
      "for tweet in tokes:\n",
      "    pos, neg = afinn_sentiment2(tweet, afinn)\n",
      "    if pos > neg:\n",
      "        pos2.append((' '.join(tweet), pos, neg))\n",
      "    elif neg > pos:\n",
      "        neg2.append((' '.join(tweet), pos, neg))\n",
      "\n",
      "print (1.0*len(pos2)+1.0)/(len(pos2)+len(neg2)+1.0)*100.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}