import ConfigParser
from TwitterAPI import TwitterAPI
import re
from StringIO import StringIO
from zipfile import ZipFile
from urllib import urlopen
import sys
import pickle

def tokenize(text):
    return re.sub('\W+', ' ', text.lower()).split()

def afinn_sentiment2(terms, afinn, verbose=False):
    pos = 0
    neg = 0
    
    for t in terms:
        if t in afinn:
            if verbose:
                print '\t%s=%d' % (t, afinn[t])
            if afinn[t] > 0:
                pos += afinn[t]
            else:
                neg += -1 * afinn[t]
    return pos, neg

url = urlopen('http://www2.compute.dtu.dk/~faan/data/AFINN.zip')
zipfile = ZipFile(StringIO(url.read()))
afinn_file = zipfile.open('AFINN/AFINN-111.txt')

afinn = dict()
for line in afinn_file:
    sections = line.strip().split()
    if len(sections) == 2:
        afinn[sections[0]] = int(sections[1])

tweets = pickle.load(open(sys.argv[1]+'.pkl','rb'))
print 'read %d tweets' % len(tweets)
tokes = [tokenize(t['text']) for t in tweets]
pos2 = []
neg2 = []

for tweet in tokes:
    pos, neg = afinn_sentiment2(tweet, afinn)
    if pos > neg:
        pos2.append((' '.join(tweet), pos, neg))
    elif neg > pos:
        neg2.append((' '.join(tweet), pos, neg))

print (1.0*len(pos2)+1.0)/(len(pos2)+len(neg2)+1.0)*100.0
